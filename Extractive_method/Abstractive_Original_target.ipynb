{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Abstractive_Original_target.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkiwYSteywpi",
        "outputId": "b71064fe-bb13-4aee-9a7f-d5db9849e9ce"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov 22 07:42:49 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    46W /  70W |   9179MiB / 15079MiB |     98%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkzLWqDwTFYz"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "\n",
        "# import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import glob\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWGzZBifTXVU",
        "scrolled": true,
        "outputId": "1ac63f09-8271-46f6-8526-6ff85b9d0a0f"
      },
      "source": [
        "!git clone 'https://github.com/ThanhChinhBK/vietnews'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vietnews'...\n",
            "remote: Enumerating objects: 143827, done.\u001b[K\n",
            "remote: Counting objects: 100% (143827/143827), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143815/143815), done.\u001b[K\n",
            "remote: Total 143827 (delta 11), reused 143827 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (143827/143827), 194.68 MiB | 20.63 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Checking out files: 100% (150704/150704), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qds5oLaUM_w"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "def flatten_list(lists):\n",
        "  flat_list = [item for sublist in lists for item in sublist]\n",
        "  return flat_list\n",
        "\n",
        "def build_dict(lists):\n",
        "  word2index = {}\n",
        "  word2count = {}\n",
        "  index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "  n_words = 2  # Count SOS and EOS\n",
        "\n",
        "  flatten = ''.join(flatten_list(lists))\n",
        "  for word in flatten.split(' '):\n",
        "    if word not in word2index:\n",
        "      word2index[word] = n_words\n",
        "      word2count[word] = 1\n",
        "      index2word[n_words] = word\n",
        "      n_words += 1\n",
        "    else:\n",
        "      word2count[word] += 1\n",
        "  \n",
        "  return word2index, word2count, index2word, n_words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjXgjLHMbE6j"
      },
      "source": [
        "def readLangs(directory):\n",
        "    files_path = glob.glob(f'{directory}/*')\n",
        "    print(\"Reading lines...\")\n",
        "    sample = []\n",
        "    text = []\n",
        "    target = []\n",
        "    for file in os.listdir(directory):\n",
        "      with open(os.path.join(directory,file), 'r') as f:\n",
        "          file_content = f.readlines()\n",
        "          abstract = file_content[2]\n",
        "          body = ' '.join(file_content[3:]).replace('\\n', '').replace('.\\n', '').rstrip(\"\\n\")\n",
        "          pairs = [abstract, body]\n",
        "          sample.append(pairs)\n",
        "          text.append(body)\n",
        "          target.append(abstract)\n",
        "\n",
        "    return text, target, sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZlsFoCfBKH",
        "outputId": "ec274340-9208-4d31-9ce4-94ca9bc1e381"
      },
      "source": [
        "def prepareData(directory):\n",
        "    input_lang, output_lang, pairs = readLangs(directory)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    word2index, word2count, index2word, n_words = build_dict(input_lang)\n",
        "    print(\"Counted words:\")\n",
        "    print(n_words)\n",
        "\n",
        "    return input_lang, output_lang, pairs, word2index, word2count, index2word, n_words\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs, word2index, word2count, index2word, n_words = prepareData('./vietnews/data/train_tokenized')\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 105418 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "309489\n",
            "['Hai hạ_nghị_sĩ Mỹ chào_đón nồng_nhiệt chuyến thăm tuần tới của Thủ_tướng Nguyễn_Xuân_Phúc , đồng_thời hy_vọng sự_kiện giúp làm sâu_rộng quan_hệ kinh_tế , quốc_phòng .\\n', ' Hạ_nghị_sĩ Joaquin_Castro , bang Texas và Hạ_nghị_sĩ Ann_Wagner , bang Missouri . \" Tôi hy_vọng chuyến thăm của Thủ_tướng Phúc giúp làm sâu_rộng quan_hệ kinh_tế của hai nước chúng_ta , tăng_cường hợp_tác quốc_phòng và tăng_cường ưu_tiên nhân_quyền trong khu_vực . Mỹ và Việt_Nam , cùng các nước thành_viên ASEAN và đối_tác khu_vực , có_thể vun_đắp một châu_Á - Thái_Bình_Dương ổn_định và thịnh_vượng hơn \" , Hạ_nghị_sĩ Joaquin_Castro , bang Texas , hôm 23/5 cho_biết trong thông_cáo cùng Hạ_nghị_sĩ Ann_Wagner , bang Missouri . Castro cho biết ông rất vui được chào_đón Thủ_tướng Phúc tới Mỹ , và nhắc lại chuyến thăm Việt_Nam khi tháp_tùng cựu tổng_thống Barack_Obama năm_ngoái . \" Được tận_mắt chứng_kiến tầm quan_trọng của mối quan_hệ an_ninh , kinh_tế giữa chúng_ta , tôi một lần nữa xác_nhận đánh_giá cao ý_nghĩa quan_hệ đối_tác Mỹ - Việt \" , ông Castro cho_hay . Ông Castro và bà Wagner là đồng chủ_tịch Uỷ_ban Quốc_hội về ASEAN . Bà Wagner cũng chào_đón nồng_nhiệt tới Thủ_tướng Phúc và tin rằng hai nước sẽ thúc_đẩy quan_hệ song_phương thông_qua việc thiết_lập Uỷ_ban Quốc_hội Mỹ về ASEAN . \" Việt_Nam là một đối_tác thương_mại quan_trọng với Mỹ và bang Missouri , và chúng_ta sẽ làm_việc nhằm thúc_đẩy các cơ_hội xuyên Thái_Bình_Dương , có ý_nghĩa thiết_yếu với các công_nhân , gia_đình và doanh_nghiệp của chúng_ta \" , Hạ_nghị_sĩ Ann_Wagner , nhấn_mạnh . Thủ_tướng Nguyễn_Xuân_Phúc sẽ thăm chính_thức Mỹ từ ngày 29/5 , và gặp Tổng_thống Mỹ Donald_Trump tại Nhà_Trắng vào ngày 31/5 . Hai lãnh_đạo sẽ thảo_luận về các biện_pháp nhằm thúc_đẩy quan_hệ đối_tác toàn_diện , đặc_biệt trên các lĩnh_vực chính_trị , ngoại_giao , kinh_tế , thương_mại , giáo_dục , khắc_phục hậu_quả chiến_tranh , các vấn_đề khu_vực và quốc_tế . Thủ_tướng dự_kiến gặp một_số nghị_sĩ và bộ_trưởng Mỹ , dự toạ_đàm và gặp các doanh_nghiệp Mỹ , phát_biểu tại Quỹ Di_sản , gặp_gỡ cộng_đồng người Việt_Nam tại Mỹ . Tại thành_phố New_York , Thủ_tướng sẽ gặp Tổng_Thư_ký Liên_Hợp_Quốc_Antonio_Guterres và dự lễ kỷ_niệm 40 năm Việt_Nam gia_nhập tổ_chức này . Trọng_Giáp   Hạ_nghị_sĩ Joaquin_Castro , bang Texas và Hạ_nghị_sĩ Ann_Wagner , bang Missouri .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGJNoPZ9VeC_"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrk2vbs7YmWG"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNL68PqFYpba"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=2000):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Bxx7PxYwEm"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [word2index.get(word,10) for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0N3zSoIYwcp"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=2000):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNth5kJXZF1I"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE8KjP9SZKgS"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(pairs[i])\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in tqdm(range(1, n_iters + 1)):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cekKEm_ZM62"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH0oFkhgZP7p"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=2000):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkzeAX0IZSdu"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zovpe5KfZW8C",
        "outputId": "92939603-0103-4751-b5f7-34d43124e4ff"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 600, print_every=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/600 [00:04<49:20,  4.94s/it]\u001b[A\n",
            "  0%|          | 2/600 [00:06<39:55,  4.01s/it]\u001b[A\n",
            "  0%|          | 3/600 [00:22<1:15:33,  7.59s/it]\u001b[A\n",
            "  1%|          | 4/600 [00:28<1:09:54,  7.04s/it]\u001b[A\n",
            "  1%|          | 5/600 [00:31<57:42,  5.82s/it]  \u001b[A\n",
            "  1%|          | 6/600 [00:37<57:02,  5.76s/it]\u001b[A\n",
            "  1%|          | 7/600 [00:43<58:57,  5.96s/it]\u001b[A\n",
            "  1%|▏         | 8/600 [00:47<53:47,  5.45s/it]\u001b[A\n",
            "  2%|▏         | 9/600 [00:51<47:17,  4.80s/it]\u001b[A\n",
            "  2%|▏         | 10/600 [00:55<47:28,  4.83s/it]\u001b[A\n",
            "  2%|▏         | 11/600 [01:04<57:16,  5.83s/it]\u001b[A\n",
            "  2%|▏         | 12/600 [01:07<50:05,  5.11s/it]\u001b[A\n",
            "  2%|▏         | 13/600 [01:10<44:54,  4.59s/it]\u001b[A\n",
            "  2%|▏         | 14/600 [01:17<51:40,  5.29s/it]\u001b[A\n",
            "  2%|▎         | 15/600 [01:31<1:15:23,  7.73s/it]\u001b[A\n",
            "  3%|▎         | 16/600 [01:40<1:18:32,  8.07s/it]\u001b[A\n",
            "  3%|▎         | 17/600 [01:42<1:02:10,  6.40s/it]\u001b[A\n",
            "  3%|▎         | 18/600 [01:51<1:09:09,  7.13s/it]\u001b[A\n",
            "  3%|▎         | 19/600 [01:55<59:39,  6.16s/it]  \u001b[A\n",
            "  3%|▎         | 20/600 [01:59<54:27,  5.63s/it]\u001b[A\n",
            "  4%|▎         | 21/600 [02:02<46:31,  4.82s/it]\u001b[A\n",
            "  4%|▎         | 22/600 [02:08<48:26,  5.03s/it]\u001b[A\n",
            "  4%|▍         | 23/600 [02:17<59:15,  6.16s/it]\u001b[A\n",
            "  4%|▍         | 24/600 [02:24<1:03:38,  6.63s/it]\u001b[A\n",
            "  4%|▍         | 25/600 [02:28<53:54,  5.63s/it]  \u001b[A\n",
            "  4%|▍         | 26/600 [02:34<55:54,  5.84s/it]\u001b[A\n",
            "  4%|▍         | 27/600 [02:46<1:13:36,  7.71s/it]\u001b[A\n",
            "  5%|▍         | 28/600 [02:59<1:28:41,  9.30s/it]\u001b[A\n",
            "  5%|▍         | 29/600 [03:04<1:16:25,  8.03s/it]\u001b[A\n",
            "  5%|▌         | 30/600 [03:10<1:10:12,  7.39s/it]\u001b[A\n",
            "  5%|▌         | 31/600 [03:13<58:35,  6.18s/it]  \u001b[A\n",
            "  5%|▌         | 32/600 [03:16<49:56,  5.28s/it]\u001b[A\n",
            "  6%|▌         | 33/600 [03:18<39:06,  4.14s/it]\u001b[A\n",
            "  6%|▌         | 34/600 [03:22<39:02,  4.14s/it]\u001b[A\n",
            "  6%|▌         | 35/600 [03:28<45:10,  4.80s/it]\u001b[A\n",
            "  6%|▌         | 36/600 [03:33<44:44,  4.76s/it]\u001b[A\n",
            "  6%|▌         | 37/600 [03:40<52:06,  5.55s/it]\u001b[A\n",
            "  6%|▋         | 38/600 [03:45<48:43,  5.20s/it]\u001b[A\n",
            "  6%|▋         | 39/600 [03:49<44:43,  4.78s/it]\u001b[A\n",
            "  7%|▋         | 40/600 [03:57<54:22,  5.83s/it]\u001b[A\n",
            "  7%|▋         | 41/600 [04:05<59:47,  6.42s/it]\u001b[A\n",
            "  7%|▋         | 42/600 [04:11<58:54,  6.33s/it]\u001b[A\n",
            "  7%|▋         | 43/600 [04:15<52:42,  5.68s/it]\u001b[A\n",
            "  7%|▋         | 44/600 [04:24<1:02:57,  6.79s/it]\u001b[A\n",
            "  8%|▊         | 45/600 [04:28<52:40,  5.70s/it]  \u001b[A\n",
            "  8%|▊         | 46/600 [04:39<1:07:32,  7.31s/it]\u001b[A\n",
            "  8%|▊         | 47/600 [04:43<1:00:26,  6.56s/it]\u001b[A\n",
            "  8%|▊         | 48/600 [04:50<1:00:57,  6.63s/it]\u001b[A\n",
            "  8%|▊         | 49/600 [04:56<58:21,  6.35s/it]  \u001b[A\n",
            "  8%|▊         | 50/600 [05:06<1:09:25,  7.57s/it]\u001b[A\n",
            "  8%|▊         | 51/600 [05:11<1:00:11,  6.58s/it]\u001b[A\n",
            "  9%|▊         | 52/600 [05:16<57:41,  6.32s/it]  \u001b[A\n",
            "  9%|▉         | 53/600 [05:25<1:04:40,  7.09s/it]\u001b[A\n",
            "  9%|▉         | 54/600 [05:33<1:05:32,  7.20s/it]\u001b[A\n",
            "  9%|▉         | 55/600 [05:43<1:13:29,  8.09s/it]\u001b[A\n",
            "  9%|▉         | 56/600 [05:58<1:31:17, 10.07s/it]\u001b[A\n",
            " 10%|▉         | 57/600 [06:02<1:16:31,  8.46s/it]\u001b[A\n",
            " 10%|▉         | 58/600 [06:08<1:09:48,  7.73s/it]\u001b[A\n",
            " 10%|▉         | 59/600 [06:16<1:09:20,  7.69s/it]\u001b[A\n",
            " 10%|█         | 60/600 [06:20<59:19,  6.59s/it]  \u001b[A\n",
            " 10%|█         | 61/600 [06:25<56:15,  6.26s/it]\u001b[A\n",
            " 10%|█         | 62/600 [06:33<1:01:10,  6.82s/it]\u001b[A\n",
            " 10%|█         | 63/600 [06:38<53:42,  6.00s/it]  \u001b[A\n",
            " 11%|█         | 64/600 [06:43<51:16,  5.74s/it]\u001b[A\n",
            " 11%|█         | 65/600 [06:46<44:51,  5.03s/it]\u001b[A\n",
            " 11%|█         | 66/600 [06:55<54:05,  6.08s/it]\u001b[A\n",
            " 11%|█         | 67/600 [07:00<52:52,  5.95s/it]\u001b[A\n",
            " 11%|█▏        | 68/600 [07:03<44:59,  5.07s/it]\u001b[A\n",
            " 12%|█▏        | 69/600 [07:10<49:43,  5.62s/it]\u001b[A\n",
            " 12%|█▏        | 70/600 [07:15<48:12,  5.46s/it]\u001b[A\n",
            " 12%|█▏        | 71/600 [07:20<45:27,  5.16s/it]\u001b[A\n",
            " 12%|█▏        | 72/600 [07:24<43:07,  4.90s/it]\u001b[A\n",
            " 12%|█▏        | 73/600 [07:33<54:28,  6.20s/it]\u001b[A\n",
            " 12%|█▏        | 74/600 [07:40<54:50,  6.25s/it]\u001b[A\n",
            " 12%|█▎        | 75/600 [07:47<56:32,  6.46s/it]\u001b[A\n",
            " 13%|█▎        | 76/600 [07:51<51:36,  5.91s/it]\u001b[A\n",
            " 13%|█▎        | 77/600 [08:00<59:11,  6.79s/it]\u001b[A\n",
            " 13%|█▎        | 78/600 [08:07<58:58,  6.78s/it]\u001b[A\n",
            " 13%|█▎        | 79/600 [08:10<49:51,  5.74s/it]\u001b[A\n",
            " 13%|█▎        | 80/600 [08:14<44:58,  5.19s/it]\u001b[A\n",
            " 14%|█▎        | 81/600 [08:21<49:15,  5.69s/it]\u001b[A\n",
            " 14%|█▎        | 82/600 [08:28<54:05,  6.26s/it]\u001b[A\n",
            " 14%|█▍        | 83/600 [08:41<1:09:01,  8.01s/it]\u001b[A\n",
            " 14%|█▍        | 84/600 [08:43<55:38,  6.47s/it]  \u001b[A\n",
            " 14%|█▍        | 85/600 [08:48<49:41,  5.79s/it]\u001b[A\n",
            " 14%|█▍        | 86/600 [08:59<1:04:43,  7.55s/it]\u001b[A\n",
            " 14%|█▍        | 87/600 [09:07<1:06:12,  7.74s/it]\u001b[A\n",
            " 15%|█▍        | 88/600 [09:16<1:08:21,  8.01s/it]\u001b[A\n",
            " 15%|█▍        | 89/600 [09:21<59:25,  6.98s/it]  \u001b[A\n",
            " 15%|█▌        | 90/600 [09:29<1:02:43,  7.38s/it]\u001b[A\n",
            " 15%|█▌        | 91/600 [09:41<1:14:00,  8.72s/it]\u001b[A\n",
            " 15%|█▌        | 92/600 [09:55<1:28:42, 10.48s/it]\u001b[A\n",
            " 16%|█▌        | 93/600 [09:59<1:10:45,  8.37s/it]\u001b[A\n",
            " 16%|█▌        | 94/600 [10:02<57:11,  6.78s/it]  \u001b[A\n",
            " 16%|█▌        | 95/600 [10:08<56:03,  6.66s/it]\u001b[A\n",
            " 16%|█▌        | 96/600 [10:17<1:00:20,  7.18s/it]\u001b[A\n",
            " 16%|█▌        | 97/600 [10:22<54:32,  6.51s/it]  \u001b[A\n",
            " 16%|█▋        | 98/600 [10:25<46:16,  5.53s/it]\u001b[A\n",
            " 16%|█▋        | 99/600 [10:33<53:01,  6.35s/it]\u001b[A\n",
            " 17%|█▋        | 100/600 [10:36<44:16,  5.31s/it]\u001b[A\n",
            " 17%|█▋        | 101/600 [10:47<58:15,  7.01s/it]\u001b[A\n",
            " 17%|█▋        | 102/600 [11:01<1:15:06,  9.05s/it]\u001b[A\n",
            " 17%|█▋        | 103/600 [11:05<1:02:48,  7.58s/it]\u001b[A\n",
            " 17%|█▋        | 104/600 [11:10<57:23,  6.94s/it]  \u001b[A\n",
            " 18%|█▊        | 105/600 [11:15<51:17,  6.22s/it]\u001b[A\n",
            " 18%|█▊        | 106/600 [11:18<42:41,  5.19s/it]\u001b[A\n",
            " 18%|█▊        | 107/600 [11:24<45:32,  5.54s/it]\u001b[A\n",
            " 18%|█▊        | 108/600 [11:30<46:35,  5.68s/it]\u001b[A\n",
            " 18%|█▊        | 109/600 [11:36<47:30,  5.81s/it]\u001b[A\n",
            " 18%|█▊        | 110/600 [11:40<41:44,  5.11s/it]\u001b[A\n",
            " 18%|█▊        | 111/600 [11:45<41:11,  5.05s/it]\u001b[A\n",
            " 19%|█▊        | 112/600 [11:52<46:01,  5.66s/it]\u001b[A\n",
            " 19%|█▉        | 113/600 [11:57<44:44,  5.51s/it]\u001b[A\n",
            " 19%|█▉        | 114/600 [12:03<47:14,  5.83s/it]\u001b[A\n",
            " 19%|█▉        | 115/600 [12:11<52:10,  6.45s/it]\u001b[A\n",
            " 19%|█▉        | 116/600 [12:15<44:23,  5.50s/it]\u001b[A\n",
            " 20%|█▉        | 117/600 [12:19<41:39,  5.17s/it]\u001b[A\n",
            " 20%|█▉        | 118/600 [12:40<1:18:32,  9.78s/it]\u001b[A\n",
            " 20%|█▉        | 119/600 [12:45<1:08:32,  8.55s/it]\u001b[A\n",
            " 20%|██        | 120/600 [12:51<1:01:02,  7.63s/it]\u001b[A\n",
            " 20%|██        | 121/600 [12:55<52:10,  6.54s/it]  \u001b[A\n",
            " 20%|██        | 122/600 [13:00<49:05,  6.16s/it]\u001b[A\n",
            " 20%|██        | 123/600 [13:07<51:57,  6.54s/it]\u001b[A\n",
            " 21%|██        | 124/600 [13:14<51:29,  6.49s/it]\u001b[A\n",
            " 21%|██        | 125/600 [13:19<47:11,  5.96s/it]\u001b[A\n",
            " 21%|██        | 126/600 [13:25<47:21,  5.99s/it]\u001b[A\n",
            " 21%|██        | 127/600 [13:31<47:34,  6.03s/it]\u001b[A\n",
            " 21%|██▏       | 128/600 [13:36<44:36,  5.67s/it]\u001b[A\n",
            " 22%|██▏       | 129/600 [13:47<57:45,  7.36s/it]\u001b[A\n",
            " 22%|██▏       | 130/600 [13:52<52:52,  6.75s/it]\u001b[A\n",
            " 22%|██▏       | 131/600 [13:55<44:14,  5.66s/it]\u001b[A\n",
            " 22%|██▏       | 132/600 [14:00<41:52,  5.37s/it]\u001b[A\n",
            " 22%|██▏       | 133/600 [14:06<43:53,  5.64s/it]\u001b[A\n",
            " 22%|██▏       | 134/600 [14:10<40:01,  5.15s/it]\u001b[A\n",
            " 22%|██▎       | 135/600 [14:19<49:06,  6.34s/it]\u001b[A\n",
            " 23%|██▎       | 136/600 [14:24<45:02,  5.82s/it]\u001b[A\n",
            " 23%|██▎       | 137/600 [14:30<45:48,  5.94s/it]\u001b[A\n",
            " 23%|██▎       | 138/600 [14:31<32:51,  4.27s/it]\u001b[A\n",
            " 23%|██▎       | 139/600 [14:31<24:58,  3.25s/it]\u001b[A\n",
            " 23%|██▎       | 140/600 [14:46<49:58,  6.52s/it]\u001b[A\n",
            " 24%|██▎       | 141/600 [14:50<44:54,  5.87s/it]\u001b[A\n",
            " 24%|██▎       | 142/600 [14:54<40:36,  5.32s/it]\u001b[A\n",
            " 24%|██▍       | 143/600 [15:02<45:56,  6.03s/it]\u001b[A\n",
            " 24%|██▍       | 144/600 [15:07<44:28,  5.85s/it]\u001b[A\n",
            " 24%|██▍       | 145/600 [15:11<39:54,  5.26s/it]\u001b[A\n",
            " 24%|██▍       | 146/600 [15:21<50:06,  6.62s/it]\u001b[A\n",
            " 24%|██▍       | 147/600 [15:30<55:14,  7.32s/it]\u001b[A\n",
            " 25%|██▍       | 148/600 [15:32<43:38,  5.79s/it]\u001b[A\n",
            " 25%|██▍       | 149/600 [15:37<41:11,  5.48s/it]\u001b[A\n",
            " 25%|██▌       | 150/600 [15:43<42:34,  5.68s/it]\u001b[A\n",
            " 25%|██▌       | 151/600 [15:46<36:12,  4.84s/it]\u001b[A\n",
            " 25%|██▌       | 152/600 [15:49<33:12,  4.45s/it]\u001b[A\n",
            " 26%|██▌       | 153/600 [15:59<45:03,  6.05s/it]\u001b[A\n",
            " 26%|██▌       | 154/600 [16:09<54:38,  7.35s/it]\u001b[A\n",
            " 26%|██▌       | 155/600 [16:15<51:18,  6.92s/it]\u001b[A\n",
            " 26%|██▌       | 156/600 [16:20<46:57,  6.35s/it]\u001b[A\n",
            " 26%|██▌       | 157/600 [16:33<1:01:20,  8.31s/it]\u001b[A\n",
            " 26%|██▋       | 158/600 [16:47<1:12:42,  9.87s/it]\u001b[A\n",
            " 26%|██▋       | 159/600 [16:53<1:05:32,  8.92s/it]\u001b[A\n",
            " 27%|██▋       | 160/600 [16:57<53:21,  7.28s/it]  \u001b[A\n",
            " 27%|██▋       | 161/600 [17:00<43:44,  5.98s/it]\u001b[A\n",
            " 27%|██▋       | 162/600 [17:12<56:43,  7.77s/it]\u001b[A\n",
            " 27%|██▋       | 163/600 [17:26<1:09:41,  9.57s/it]\u001b[A\n",
            " 27%|██▋       | 164/600 [17:30<58:43,  8.08s/it]  \u001b[A\n",
            " 28%|██▊       | 165/600 [17:36<52:54,  7.30s/it]\u001b[A\n",
            " 28%|██▊       | 166/600 [17:40<46:38,  6.45s/it]\u001b[A\n",
            " 28%|██▊       | 167/600 [17:50<54:15,  7.52s/it]\u001b[A\n",
            " 28%|██▊       | 168/600 [17:54<46:11,  6.41s/it]\u001b[A\n",
            " 28%|██▊       | 169/600 [17:58<40:09,  5.59s/it]\u001b[A\n",
            " 28%|██▊       | 170/600 [18:02<37:36,  5.25s/it]\u001b[A\n",
            " 28%|██▊       | 171/600 [18:16<55:58,  7.83s/it]\u001b[A\n",
            " 29%|██▊       | 172/600 [18:20<47:28,  6.65s/it]\u001b[A\n",
            " 29%|██▉       | 173/600 [18:31<56:56,  8.00s/it]\u001b[A\n",
            " 29%|██▉       | 174/600 [18:38<53:38,  7.56s/it]\u001b[A\n",
            " 29%|██▉       | 175/600 [18:43<49:07,  6.94s/it]\u001b[A\n",
            " 29%|██▉       | 176/600 [18:51<51:11,  7.24s/it]\u001b[A\n",
            " 30%|██▉       | 177/600 [18:58<49:44,  7.06s/it]\u001b[A\n",
            " 30%|██▉       | 178/600 [19:04<47:45,  6.79s/it]\u001b[A\n",
            " 30%|██▉       | 179/600 [19:14<54:08,  7.72s/it]\u001b[A\n",
            " 30%|███       | 180/600 [19:25<1:01:41,  8.81s/it]\u001b[A\n",
            " 30%|███       | 181/600 [19:37<1:07:17,  9.64s/it]\u001b[A\n",
            " 30%|███       | 182/600 [19:44<1:03:08,  9.06s/it]\u001b[A\n",
            " 30%|███       | 183/600 [19:49<53:03,  7.63s/it]  \u001b[A\n",
            " 31%|███       | 184/600 [19:52<43:41,  6.30s/it]\u001b[A\n",
            " 31%|███       | 185/600 [19:56<39:46,  5.75s/it]\u001b[A\n",
            " 31%|███       | 186/600 [20:01<38:06,  5.52s/it]\u001b[A\n",
            " 31%|███       | 187/600 [20:05<34:14,  4.97s/it]\u001b[A\n",
            " 31%|███▏      | 188/600 [20:11<36:47,  5.36s/it]\u001b[A\n",
            " 32%|███▏      | 189/600 [20:21<44:59,  6.57s/it]\u001b[A\n",
            " 32%|███▏      | 190/600 [20:30<49:59,  7.32s/it]\u001b[A\n",
            " 32%|███▏      | 191/600 [20:36<47:28,  6.96s/it]\u001b[A\n",
            " 32%|███▏      | 192/600 [20:40<41:33,  6.11s/it]\u001b[A\n",
            " 32%|███▏      | 193/600 [20:49<46:39,  6.88s/it]\u001b[A\n",
            " 32%|███▏      | 194/600 [20:51<37:01,  5.47s/it]\u001b[A\n",
            " 32%|███▎      | 195/600 [20:58<40:11,  5.95s/it]\u001b[A\n",
            " 33%|███▎      | 196/600 [21:09<49:41,  7.38s/it]\u001b[A\n",
            " 33%|███▎      | 197/600 [21:16<49:17,  7.34s/it]\u001b[A\n",
            " 33%|███▎      | 198/600 [21:21<45:17,  6.76s/it]\u001b[A\n",
            " 33%|███▎      | 199/600 [21:26<40:41,  6.09s/it]\u001b[A\n",
            " 33%|███▎      | 200/600 [21:32<40:43,  6.11s/it]\u001b[A\n",
            " 34%|███▎      | 201/600 [21:37<38:37,  5.81s/it]\u001b[A\n",
            " 34%|███▎      | 202/600 [21:40<32:12,  4.86s/it]\u001b[A\n",
            " 34%|███▍      | 203/600 [21:42<26:35,  4.02s/it]\u001b[A\n",
            " 34%|███▍      | 204/600 [21:54<43:04,  6.53s/it]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YUOUvhzZY2j"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23tqJk6qmYvR"
      },
      "source": [
        "def evaluateInput(input_sentence):\n",
        "    outputs_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
        "    print(' '.join(outputs_words))\n",
        "\n",
        "input_sentence = '''Đây là giai đoạn \"sơ sinh\", nhưng cũng là giai đoạn chuẩn bị đầy quan trọng trên bước đường tạo ra thu nhập sau này của bạn. Ở độ tuổi này chúng ta chưa có gì ngoài sức khỏe và sự nhiệt huyết, chính vì lẽ đó bạn không thể đòi hỏi một công việc với mức thu nhập cao hơn năng lực của mình được.'''\n",
        "evaluateInput(input_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}